后端涉及的相关知识：
	1.对应框架的选择，比如node后端，选择express大礼包还是koa这种轻量级的框架，框架时对流程的规范和梳理
	2.在框架的基础上，对后端代码结构进行自己的梳理，比如自己写controller，view,model，route四个文件夹，
	  通过route路由，然后在实现后端的mvc模式【model处理数据库相关数据操作，view执行渲染，controller执行业务逻辑并且和view以及model连接通讯】
	3.网站数据安全：xss,csrf,sql注入，重播攻击，ddos，网络劫持，http安全头等，数据加密解密加签解签，https证书
	4.统一的数据转化和权限校验（用户登录态和登录验证；操作数据时候的权限校验），缓存机制，数据埋点和错误统计
	  等常用功能
	5.数据库操作：增删改查【CRUD】基本操作；聚合，管道，mapreduce，事务；集群，分片；
	6.高并发的各种问题：数据的脏读，幻读，不可重复读等问题的产生以及如何解决【通过设置事务级别+加锁来实现】
					  但加锁的时候容易死锁，同时加锁的范围和事务级别的高低又会影响高并发性能；

				高并发的核心，就是选择和是的事务隔离级别+加锁，保证数据的“原子性、一致性、隔离性、持久性”的前提下，尽量给事务设置低的隔离级别，尽量缩小锁的范围；并且写代码的时候避免产生死锁【没有事务也可能产生死锁，因为系统会对增删改自动加锁】



				锁的分类：
					1.线程锁：对于代码块的锁，有的时候线程A执行某个代码块执行到一个异步操作，跳转到其他地方
					         整个时候线程B又执行整个代码块，导致里面的变量改变
					         一般都不会遇到线程锁，因为基本每个任务都是单独的实例，没用到共享变量。
					2.数据库锁：数据库级别锁【数据库锁】，表级别锁【单集合锁】，页级别锁【多文档锁】，行级别锁【单文档锁】


				如何防止死锁：...


				事务的隔离级别：【数据库事务有一个默认的隔离级别，sqlServer的事务默认隔离级别是下面的2】
				  				事务的隔离级别越高，并发能力也就越低；保证数据的“原子性、一致性、隔离性、持久性”的前提下，尽量选级别低的隔离级别

			  					1.Read uncommitted 未提交读
			  					2.Read committed  已提交读 
			  					3.Repeatable read  可重复读
			  					4.Serializable 可串行化 ：这个是最高级别，能解决所有问题，但性能很低【读取数据的时候直接锁表，改表的其他所有操作都不能执行】

							  	//不同隔离界下出现“脏读，不可重复读，幻读”的可能性
							  	隔离级别		脏读		不可重复读 	幻读
								未提交读		可能		可能			可能
								已提交读		不可能	可能			可能
								可重复读 	不可能	不可能		可能
								可串行化		不可能	不可能		不可能


				数据加锁，“死锁”，锁的让渡：下面是mongodb的锁的模式
					R ：共享锁(S)：数据可以有时候会自动加共享锁，同时自己也可以手动加
									即一个事务在读取一个数据行的时候，其他事务也可以读，但不能对该数据行进行增删改(因为增删改都是自动加排它锁)。
					W ：排它锁(X)：数据可以有时候会自动加排他锁，同时自己也可以手动加
									即一个事务在读取一个数据行的时候，其他事务不能对该数据行进行增删改，不加锁的查是可以的，加锁的查是不可以的。
					r ：意向共享锁(IS) ：数据库自动执行，不需要人工干预
					w ：意向排它锁(IX)：数据库自动执行，不需要人工干预

					乐观锁和悲观锁的理解【没必要用】：mongodb 没有乐观锁和悲观锁，这些需要自己在代码中实现

				锁的范围：文档【锁一个文档】，集合【锁整个集合】，数据库【锁整个数据库】

				事务对某行或者某张表或者整个数据库加锁，就是整个事务对整个资源声明主权，在我占领这个资源的情况下，其他事务都无权对这个资源执行我不允许的操作；
				同一个资源，可以接受多个事务的锁，就是被多个事务占领，但是有的锁是不能重复加的
				比如共享锁，事务A对表施加了共享锁，其他事务也可以添加共享锁，但不能添加排他锁
				如果事务A对表施加了排他锁，那其他任何事务都不能对表施加共享锁或排他锁，不能增删改，但可以查

				mongodb的数据库操作对应的加锁机制：

					操作 数据库级别锁 集合级别锁
					查询(query) r (意向共享锁(IS)) r (意向共享锁(IS))
					插入数据(insert） w (意向排它锁(IX)) w (意向排它锁(IX))
					删除数据(remove) w (意向排它锁(IX)) w (意向排它锁(IX))
					更新数据(update) w (意向排它锁(IX)) w (意向排它锁(IX))
					执行聚合操作(aggregation) r (意向共享锁(IS)) r (意向共享锁(IS))
					创建索引(前台创建Foreground) W (排它锁(X))
					创建索引(后台创建Background) w (意向排它锁(IX)) w (意向排它锁(IX))
					列出集合列表(List collections) r (意向共享锁(IS))
					版本4.0中修改.
					Map-reduce操作 W (排它锁(X) 和R 共享锁(IS) w (意向排它锁(IX)) and r (意向共享锁(IS))


					默认的增删改查操作本身就是原子操作，数据库自动会加锁解锁，不需要开发特地加锁
					最麻烦的是“事务”，事务虽然执行结果具有原子性，但是执行的时候，会出现各种脏读，不可重复度，幻读等问题，需要设定事务的“隔离级别”，并且给事务加尽量小的锁；













幂等 ：在数据不变的情况下，一个操作，无论执行多少次，结果都是一样的；幂等函数就是，任何时候调用，参数不变，结果不变

后台处理数据库业务逻辑：建立链接次数尽量少，多个请求尽量合并成一个请求，因为建立连接是比较费时的，损耗后台服务器，也损耗数据库服务器；
					  所以一个请求能完成的所有数据，就别分多次请求；用户端一个行为，最好是连接一次数据库

//需要一个本地数据库，一个测试数据库，分别用于本地开发和测试环境测试

数据库：mongodb【和redis类似，都是内存型数据库，先把数据放内存，然后再写磁盘里】【主要解决海量数据的访问效率问题，但它比较占资源，文件比较大，磁盘和内存需要较大】
    0.超级好用，易学，两天就看得七七八八了
	1.“nosql类型数据库”中的“文档存储”类型
	2.database【数据库】，collection【集合】，document【文档】，field【数据字段/域】，index【索引】，primary key【主键】
	3.基础：增删改查，
	  索引【提高查找速度】：如何制定高效的索引，是提升性能的核心；https://www.cnblogs.com/yu-hailong/p/7631572.html
	  					0.索引只要创建一遍，就会一直存在于数据库服务器的内存里，数据库更新，索引也会自动更新
	  					1.把集合按照特定field字段分组，其实就是把数据格式按照某些特定的key去排序，创造另一种便于查询和操作的数据格式
	  					2.索引可以看成另一种数据库中的数据，只是这个数据保存在内存中，但是操作数据的时候，索引也必须更新，就当成数据库的一部分
	  					3.索引可制定权重，搜索某个数据的时候，会按照关联索引的权重去查询，因为在内存，所以速度特别快，但是对内存要求高
	  					  
	  					4.如果不用索引，面对大批量的数据排序，数据库服务器会把用的所有数据全部塞到内存里面计算，MongoDB 将会报错 造成内存溢出，导致MongoDB报错 
	  					5.其实每一个集合内的文档，文档的“主键_id”就是它的默认索引，但基本查询不会用到这个字段的查询，索引需要自己创建索引

	  进阶：mapReduce【大批量数据处理工作分解成一个个单元执行，然后再把结果合并】：这个是核心，必须掌握【用js编写，并且基于js v8引擎解析】
	  	    mapReduce：https://www.cnblogs.com/boshen-hzb/p/10431295.html，说得非常好，其他人讲得都是垃圾
	  	    		   使用场景：复杂大型的数据操作，并返回集合数据，如果只是统计综合，平均值之类的，用聚合比较合适，因为较轻量级
	  	    			1.filter筛选，
	  	    			2.根据emit函数里的第一个参数进行分组，对应的值是第二个参数的数组，分成若干组，完成map；
	  	    			3.map产生的组的key就是emit函数里面的key，map组的value【数组】就是emit(key,value)里面的value，会把相同key的所有value集合在一起形成一个数组；
	  	    			最终reduce接收到的数据是[{key:[...values]},{key:[...values]},{key:[...values]}]
	  	    			4.而reduce里面会自动遍历这个数组的所有对象，例如上面的3个对象；
	  	    			  至于对象里面的数据如何处理，就是看reduce函数里面的逻辑了，reduce会默认遍历，然后
	  	    			  再执行reduce函数里面的逻辑，传入的参数是每一个组对象，例如{key:[...values]}
	  	    			  最终产生一个聚合数组，就是把每个组的返回值全push到数组里面
	  	    			

	  	    聚合+管道【一般用户统计平均值，求和等遍历大批量数据求值的操作】
	  	    




	4.高级：分片【增加服务器，提高数据存储量和计算速度】，复本集（也就是集群）【也是有主库和从库，主库死了，从库自动顶上】，主从数据库【主库存储线上数据，从库每隔几秒从主库获取更新数据，和主库数据保持一致，主库数据库瘫了，直接用从库顶上，这个需要手动】
mongodb单个数据库的数据结构：所以mongodb的数据库集合，实际上就是一个JSON对象

	{
		db：{
			//db下一个对象，就是一个“集合”
			"collectionA":[{//一个对象就是一个文档
					_id:ObjectId("456321456321546"),
					name:"jeff",//一个key就是对应的field
					age:24
				},{//一个对象就是一个文档
					_id:ObjectId("456321456321546"),
					name:"jeff",//一个key就是对应的field
					age:24
				}],
			"collectionB":[]
		}
	}





数据库安全：
	1.防止而已大批量查询，数据库内存溢出。
	2.给可能的大批量查询制定索引，提高效率的同时防止内存溢出【索引也不能太多，不然也会造成内存溢出】


















论坛的数据库数据结构：数据库结构设计，很容易关联错误导致数据前后矛盾，毕业设计用到的一个软件可以检测这个问题【实体，主键，外键设置】
					最复杂的功能就是评论嵌套的设计：如何存档数据方便查询

{
	ab：{
		//users,articles,comments是三个集合，一般经常用到MapReduce命令来遍历一个集合，比如用MapReduce遍历users
		users:[{
			//下面是内容
			uid,
			userName,//帐号
			passward,//密码
			phone,
			name,//真实姓名
			age,
			sex,
			favName,//网名|昵称|花名【唯一，大家网名不能相互重复】
			charts:[{type,data}]//data是图标的数据，对数据格式的校验前端完成，后台和数据库都不做处理

			//下面是关联key：关联人，文章，说说|评论
			fans:[uid]//粉丝
			attention:[{uid,attentionLevel}]//关注哪些人
			favComment：[uid]//点赞了哪些评论|说说
			favArticle：[aid]//点赞了哪些文章
			article:[aid,aid....]//文章
			collect:[aid,aid...],//收藏
			comment:[cid]//写了哪些评论|说说
			msgboard:[cid]//留言板，谁给这个人留言了
		}],

		//文章的查询特别多，文章相对来说比“说说"少很多"，且有些字段也不一样，没必要放一个集合，逻辑上也说不通，性能上也不好
		articles:[{//业务逻辑处理的时候，要特别注意是“文章”|“说说”|留言

			//下面是内容
			aid,//唯一id
			time,//时间
			title,//标题
			content,//内容

			//下面是关联key
			tag:["desc1","desc2"....]//标签
			comment:[aid,aid]//评论：只有针对文章的评论，其他都没有
			uid,//谁写的 
			atuid,//作者@谁 
			faver：【uid】//点赞 
			relay:[uid,uid]//转发 
		}]

		//谁在什么时候对谁说了什么话，哪些人支持点赞
		comments:[{//注意，这个不光是相互评论；还有一个是个人主页留言板的第一层评论，

			//下面是内容
			cid,//唯一id
			time,
			content,

			//下面是关联key
			uid,//谁写的
			target:{//针对谁
				uid,//在某人留言板留言
				aid,//在某个文章下留言
				cid,//针对某个评论或说说留言
				noid//不针对任何人，文章，评论|说说；也就是自己发独立的说说
			}
			faver：【uid】//点赞
		}]

	}
}
		




关于前后端数据传输：


Form元素的EncType属性表明提交数据的格式 用Enctype属性指定将数据回发到服务器时浏览器使用的编码类型，默认的缺省值是“application/x-www-form-urlencoded”。


下边是说明：
application/x-www-form-urlencoded：窗体数据被编码为名称/值对。这是标准的编码格式。


multipart/form-data：窗体数据被编码为一条消息，页上的每个控件对应消息中的一个部分。


text/plain：窗体数据以纯文本形式进行编码，其中不含任何控件或格式字符。

补充
form的enctype属性为编码方式，常用有两种：


application/x-www-form-urlencoded和 multipart/form-data，


当action为get时候，浏览器用x-www-form-urlencoded的编码方式把form 数据转换成一个字串（name1=value1& amp;name2=value2...），然后把这个字串append到url后面，用?分割，加载这个新的url。


当action为post时候，浏览器把form数据封装到http body中，然后发送到server。如果没有type=file的控件，用默认的application/x-www-form-urlencoded 就可以了。但是如果有type=file的话，就要用到multipart/form-data了。浏览器会把整个表单以控件为单位分割，并为每个部分加 上 Content-Disposition(form-data或者file),Content-Type(默认为text/plain),name(控件 name)等信息，并加上分割符(boundary)。

“application/x-www-form-urlencoded”在向服务器发送大量的文本、包含非ASCII字符的文本或二进制数据时这种编码方式效率很低。



    在文件上载时，所使用的编码类型应当是“multipart/form-data”，它既可以发送文本数据，也支持二进制数据上载。

 

    Browser端<form>表单的ENCTYPE属性值为multipart/form-data，它告诉我们传输的数据要用到多媒体传输 协议，由于多媒体传输的都是大量的数据，所以规定上传文件必须是post方法，<input>的type属性必须是file。

    上传数据的类型【例如multipart/form-data; boundary=----WebKitFormBoundaryBjCL9yOqUJg6HYxg】，从this.req.headers["content-type"].split(";")[0]中获取到类型【例如：multipart/form-data类型】
    上传的数据，是从this.req.on("data",function(data){ 处理data数据 })中获取上传数据，然后在this.req.on("end",function(data){ 数据完全接受完成后的业务处理 })